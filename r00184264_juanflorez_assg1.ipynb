{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r00184264_juanflorez_assg1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRnMCTAG2ESCj8J8gQJ0D4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanflorezVe/COMP9058_lab1/blob/master/r00184264_juanflorez_assg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJivgFpXEloh"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9KfcjsB09Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f76ce82-198e-4307-8aa4-b5aaebbb2048"
      },
      "source": [
        "# Copying vervatim the code from the assignment\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "experiment = tf.Variable([1,2,3])\n",
        "print(tf.divide(tf.reduce_sum(experiment),experiment.shape[0]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "tf.Tensor(2.0, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1I7TLooA7uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e996d6-13d2-45f0-a9a2-5be562c8920e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load the training and test data    \n",
        "(tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
        "\n",
        "# reshape the feature data\n",
        "tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
        "te_x = te_x.reshape(te_x.shape[0], 784)\n",
        "\n",
        "# noramlise feature data\n",
        "tr_x = tr_x / 255.0\n",
        "te_x = te_x / 255.0\n",
        "\n",
        "print( \"Shape of training features \", tr_x.shape)\n",
        "print( \"Shape of test features \", te_x.shape)\n",
        "\n",
        "\n",
        "# one hot encode the training labels and get the transpose\n",
        "tr_y = np_utils.to_categorical(tr_y,10)\n",
        "tr_y = tr_y.T\n",
        "print (\"Shape of training labels \", tr_y.shape)\n",
        "\n",
        "# one hot encode the test labels and get the transpose\n",
        "te_y = np_utils.to_categorical(te_y,10)\n",
        "te_y = te_y.T\n",
        "print (\"Shape of testing labels \", te_y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Shape of training features  (60000, 784)\n",
            "Shape of test features  (10000, 784)\n",
            "Shape of training labels  (10, 60000)\n",
            "Shape of testing labels  (10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLfLKaoqUF2e"
      },
      "source": [
        "#Let's insert 784 parameters to each neuron\n",
        "# A = W.T * X + b\n",
        "# layer_pass will take the x matrix, pass it to the l layer applying the w weights and adding the b bias\n",
        "#NeuralNetworksW5 slide 11\n",
        "# m = 60000\n",
        "# n = 784\n",
        "# p = 200\n",
        "def relu_layer_pass(w, x, b):\n",
        "  t = tf.matmul(w,x)\n",
        "  l = tf.add(t,b)\n",
        "  h = tf.nn.relu(l)\n",
        "  return h\n",
        "\n",
        "def softmax_layer_pass(w, x, b):\n",
        "  t = tf.matmul(w,x)\n",
        "  l = tf.add(t,b)\n",
        "  h = tf.nn.softmax(l)\n",
        "  return h\n",
        "\n",
        "def loss_function(predicted, expected, x=None):\n",
        "  E = tf.math.subtract(predicted, expected)\n",
        "  print(E.shape)\n",
        "  db = tf.divide(tf.reduce_sum(E),E.shape[0])\n",
        "  d_lambda = tf.divide((x * tf.transpose(E)), E.shape[0])\n",
        "  return d_lambda"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHo4xMShUmHX"
      },
      "source": [
        "def forward_pass(w1, w2, b1, b2, x):\n",
        "  #pass the first layer\n",
        "  h1 = relu_layer_pass(w1,x,b1)\n",
        "  #pass the second layer\n",
        "  h2 = softmax_layer_pass(w2,h1,b2)\n",
        "  return h2\n",
        "  #print(H1.shape)\n",
        "  #print(H2.shape)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3EDtg1FocI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf3cc72-7db6-43db-cbdd-66809afe21f0"
      },
      "source": [
        "# from lecture (VectorizedLogistiRegression, page 50) March 9th.... \n",
        "# We have a set of trainning of 60000 rows (instances)\n",
        "# and 748 columns ( Features)\n",
        "# Our X vector has 784 rows (as fetarues) and 60000 columns (instances)\n",
        "X = tf.Variable(tr_x.T, dtype = tf.float32)\n",
        "print(\"X shape is {}\".format( X.shape))\n",
        "# Let's create a vector W1 with the number of weights (784) for each neuron in one row\n",
        "# so, it means 200 rows and 784 columns ( Features) for layer 1\n",
        "W1 = tf.Variable(tf.random.normal([ 200,784], mean=0.0, stddev=0.05))\n",
        "#The bias for the first layer of 200 neurons will be a vecoter of 200 rows (1 per neuron)\n",
        "# and 1 column\n",
        "B1 = tf.Variable(tf.random.uniform(shape=[200,1],dtype=tf.float32))\n",
        "\n",
        "\n",
        "print (\"W1 shape is{}\".format(W1.shape))\n",
        "print (\"B1 shape is{}\".format(B1.shape))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape is (784, 60000)\n",
            "W1 shape is(200, 784)\n",
            "B1 shape is(200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRf3fRXNqhyL",
        "outputId": "02a28da1-e8e3-4ac1-e1db-1f152df674c9"
      },
      "source": [
        "#The second layer:\n",
        "# W2 has 10 rows (as it has 10 possible classes)\n",
        "W2 = tf.Variable(tf.random.uniform(shape=[10,200], dtype=tf.float32, minval=-0.1, maxval=0.1))\n",
        "B2 = tf.Variable(tf.random.uniform(shape=[10,1], dtype=tf.float32))\n",
        "print (\"W2 shape is{}\".format(W2.shape))\n",
        "print (\"B2 shape is{}\".format(B2.shape))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W2 shape is(10, 200)\n",
            "B2 shape is(10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC6WZg8RFp19"
      },
      "source": [
        "Question 1, section a. Question1_1_1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcn1nNpPu-VQ"
      },
      "source": [
        "learning_rate=0.01\n",
        "iterations=70\n",
        "adam_optimizer=tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKIsW-7RvF-p"
      },
      "source": [
        "# Rgression loop\n",
        "#for i in range(iterations):\n",
        "#  with tf.GradientTape() as tape:\n",
        "#    H = forward_pass(W1,W2,B1,B2,X)\n",
        "#    current_loss = loss_function(H, tr_y) # 2 vectors witht the derivated to update W1 and W2\n",
        "  \n",
        "    "
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU_kVxL341KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8738f9-19d0-4184-efc8-90fc74ab6dbd"
      },
      "source": [
        "#Unit tests\n",
        "xu = tf.Variable([[0.3,0.2,0.1],\n",
        "                  [0.7,0.6,0.5],\n",
        "                  [0.2,0.2,0.2]])\n",
        "big = tf.Variable([6.0,8.0,10.0])\n",
        "small = tf.Variable([5.0,7.0,9.0])\n",
        "print(loss_function(big, small, xu)) # should be xu/3\n",
        "print(loss_function(small, big, xu)) # should be -xu/3"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,)\n",
            "tf.Tensor(\n",
            "[[0.1        0.06666667 0.03333334]\n",
            " [0.23333333 0.2        0.16666667]\n",
            " [0.06666667 0.06666667 0.06666667]], shape=(3, 3), dtype=float32)\n",
            "(3,)\n",
            "tf.Tensor(\n",
            "[[-0.1        -0.06666667 -0.03333334]\n",
            " [-0.23333333 -0.2        -0.16666667]\n",
            " [-0.06666667 -0.06666667 -0.06666667]], shape=(3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8I_oeqYZvUW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}