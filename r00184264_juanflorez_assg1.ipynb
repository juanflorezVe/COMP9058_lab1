{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r00184264_juanflorez_assg1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNebWARmf3PbyfwJg4xCIdi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanflorezVe/COMP9058_lab1/blob/master/r00184264_juanflorez_assg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJivgFpXEloh"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9KfcjsB09Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f76ce82-198e-4307-8aa4-b5aaebbb2048"
      },
      "source": [
        "# Copying vervatim the code from the assignment\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "experiment = tf.Variable([1,2,3])\n",
        "print(tf.divide(tf.reduce_sum(experiment),experiment.shape[0]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "tf.Tensor(2.0, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1I7TLooA7uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e996d6-13d2-45f0-a9a2-5be562c8920e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load the training and test data    \n",
        "(tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
        "\n",
        "# reshape the feature data\n",
        "tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
        "te_x = te_x.reshape(te_x.shape[0], 784)\n",
        "\n",
        "# noramlise feature data\n",
        "tr_x = tr_x / 255.0\n",
        "te_x = te_x / 255.0\n",
        "\n",
        "print( \"Shape of training features \", tr_x.shape)\n",
        "print( \"Shape of test features \", te_x.shape)\n",
        "\n",
        "\n",
        "# one hot encode the training labels and get the transpose\n",
        "tr_y = np_utils.to_categorical(tr_y,10)\n",
        "tr_y = tr_y.T\n",
        "print (\"Shape of training labels \", tr_y.shape)\n",
        "\n",
        "# one hot encode the test labels and get the transpose\n",
        "te_y = np_utils.to_categorical(te_y,10)\n",
        "te_y = te_y.T\n",
        "print (\"Shape of testing labels \", te_y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Shape of training features  (60000, 784)\n",
            "Shape of test features  (10000, 784)\n",
            "Shape of training labels  (10, 60000)\n",
            "Shape of testing labels  (10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLfLKaoqUF2e"
      },
      "source": [
        "#Let's insert 784 parameters to each neuron\n",
        "# A = W.T * X + b\n",
        "# layer_pass will take the x matrix, pass it to the l layer applying the w weights and adding the b bias\n",
        "#NeuralNetworksW5 slide 11\n",
        "# m = 60000\n",
        "# n = 784\n",
        "# p = 200\n",
        "def relu_layer_pass(w, x, b):\n",
        "  t = tf.matmul(w,x)\n",
        "  l = tf.add(t,b)\n",
        "  h = tf.nn.relu(l)\n",
        "  return h\n",
        "\n",
        "def softmax_layer_pass(w, x, b):\n",
        "  t = tf.matmul(w,x)\n",
        "  l = tf.add(t,b)\n",
        "  h = tf.nn.softmax(l)\n",
        "  return h\n",
        "\n",
        "#TODO: X is the matrix with the training instances,\n",
        "#but I need a function that given an Error, E, and a\n",
        "# vector with inputs, gives me the d_lambda and db\n",
        "\n",
        "def loss_function(E, x=None):\n",
        "  db = tf.divide(tf.reduce_sum(E),E.shape[0])\n",
        "  print(\"shape of x {}, shape of E transposed {}\".\n",
        "        format(x.shape, tf.transpose(E).shape))\n",
        "  temp = tf.matmul(x, tf.transpose(E))\n",
        "  d_lambda = tf.divide(temp, E.shape[0])\n",
        "  return db, d_lambda"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHo4xMShUmHX"
      },
      "source": [
        "def forward_pass(w1, w2, b1, b2, x):\n",
        "  #pass the first layer\n",
        "  h1 = relu_layer_pass(w1,x,b1)\n",
        "  #pass the second layer\n",
        "  h2 = softmax_layer_pass(w2,h1,b2)\n",
        "  return h2\n",
        "  #print(H1.shape)\n",
        "  #print(H2.shape)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3EDtg1FocI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017263d0-73c2-40ef-b3e3-1a3c7920e026"
      },
      "source": [
        "# from lecture (VectorizedLogistiRegression, page 50) March 9th.... \n",
        "# We have a set of trainning of 60000 rows (instances)\n",
        "# and 748 columns ( Features)\n",
        "# Our X vector has 784 rows (as fetarues) and 60000 columns (instances)\n",
        "X = tf.transpose(tr_x)\n",
        "X = tf.cast(X, tf.float32)\n",
        "print(\"X shape is {}\".format( X.shape))\n",
        "# Let's create a vector W1 with the number of weights (784) for each neuron in one row\n",
        "# so, it means 200 rows and 784 columns ( Features) for layer 1\n",
        "W1 = tf.Variable(tf.random.normal([ 200,784], mean=0.0, stddev=0.05))\n",
        "#The bias for the first layer of 200 neurons will be a vecoter of 200 rows (1 per neuron)\n",
        "# and 1 column\n",
        "B1 = tf.Variable(tf.random.uniform(shape=[200,1],dtype=tf.float32))\n",
        "\n",
        "\n",
        "print (\"W1 shape is{}\".format(W1.shape))\n",
        "print (\"B1 shape is{}\".format(B1.shape))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape is (784, 60000)\n",
            "W1 shape is(200, 784)\n",
            "B1 shape is(200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRf3fRXNqhyL",
        "outputId": "ad081552-337a-4a53-c07b-5fa82c8aed3a"
      },
      "source": [
        "#The second layer:\n",
        "# W2 has 10 rows (as it has 10 possible classes)\n",
        "W2 = tf.Variable(tf.random.uniform(shape=[10,200], dtype=tf.float32, minval=-0.1, maxval=0.1))\n",
        "B2 = tf.Variable(tf.random.uniform(shape=[10,1], dtype=tf.float32))\n",
        "print (\"W2 shape is{}\".format(W2.shape))\n",
        "print (\"B2 shape is{}\".format(B2.shape))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W2 shape is(10, 200)\n",
            "B2 shape is(10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC6WZg8RFp19"
      },
      "source": [
        "Question 1, section a. Question1_1_1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcn1nNpPu-VQ"
      },
      "source": [
        "learning_rate=0.01\n",
        "iterations=1\n",
        "adam_optimizer=tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cKIsW-7RvF-p",
        "outputId": "e93660f6-2084-4f01-bf33-208d52fa7a43"
      },
      "source": [
        "# Rgression loop\n",
        "for i in range(iterations):\n",
        "  H = forward_pass(W1,W2,B1,B2,X)\n",
        "  E = tf.subtract(H,tr_y)\n",
        "  print(\"E is {}\".format(E))\n",
        "  print(\"W1 is {}\".format(W1))\n",
        "  print(\"H is {}\".format(H))\n",
        "  print(\"X is {}\".format(X))\n",
        "  db1, dl1 = loss_function(E, X)\n",
        "  B1 = tf.subtract(B1, tf.scalar_mul(learning_rate, db1))\n",
        "  secondpart = tf.scalar_mul(learning_rate, dl1)\n",
        "  W1 = tf.subtract(W1,secondpart)\n",
        "print(\"Done\") \n",
        "    "
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E is [[ 2.18038222e-05 -9.99991119e-01 -9.99981642e-01 ...  2.52526279e-05\n",
            "  -9.99986649e-01  1.59846986e-05]\n",
            " [ 1.53523506e-05  2.13291478e-05  2.01580879e-05 ...  1.94460954e-05\n",
            "   1.58945859e-05  1.89139937e-05]\n",
            " [ 2.55389641e-05  1.71687934e-05  1.39249441e-05 ...  3.44154323e-05\n",
            "   1.23632235e-05  1.26235245e-05]\n",
            " ...\n",
            " [ 2.10332837e-05  1.15374787e-05  1.20182422e-05 ...  1.97294539e-05\n",
            "   1.60928867e-05  1.38193564e-05]\n",
            " [ 1.68148854e-05  1.54480895e-05  1.58720268e-05 ...  1.35970549e-05\n",
            "   1.66821701e-05  1.30497301e-05]\n",
            " [-9.99975085e-01  1.07741898e-05  1.69434879e-05 ...  1.87824407e-05\n",
            "   1.40612938e-05  2.07337162e-05]]\n",
            "W1 is <tf.Variable 'Variable:0' shape=(200, 784) dtype=float32, numpy=\n",
            "array([[-0.10522868, -0.01616263, -0.11177293, ...,  0.08140687,\n",
            "         0.04514502,  0.05821004],\n",
            "       [-0.00986829, -0.03909342, -0.00266622, ..., -0.00720748,\n",
            "        -0.05664061,  0.05862942],\n",
            "       [ 0.00145401,  0.01184191, -0.03829617, ...,  0.00057218,\n",
            "         0.01849945,  0.09402838],\n",
            "       ...,\n",
            "       [ 0.08207065,  0.01210983, -0.03585204, ..., -0.08122972,\n",
            "        -0.10364083, -0.00752265],\n",
            "       [ 0.01648138, -0.08096708,  0.05413422, ..., -0.11260859,\n",
            "        -0.03691637,  0.07406063],\n",
            "       [ 0.09048734,  0.00211168, -0.03599166, ...,  0.02430364,\n",
            "         0.02879244, -0.09946348]], dtype=float32)>\n",
            "H is [[2.18038222e-05 8.87106034e-06 1.83528537e-05 ... 2.52526279e-05\n",
            "  1.33444619e-05 1.59846986e-05]\n",
            " [1.53523506e-05 2.13291478e-05 2.01580879e-05 ... 1.94460954e-05\n",
            "  1.58945859e-05 1.89139937e-05]\n",
            " [2.55389641e-05 1.71687934e-05 1.39249441e-05 ... 3.44154323e-05\n",
            "  1.23632235e-05 1.26235245e-05]\n",
            " ...\n",
            " [2.10332837e-05 1.15374787e-05 1.20182422e-05 ... 1.97294539e-05\n",
            "  1.60928867e-05 1.38193564e-05]\n",
            " [1.68148854e-05 1.54480895e-05 1.58720268e-05 ... 1.35970549e-05\n",
            "  1.66821701e-05 1.30497301e-05]\n",
            " [2.49140576e-05 1.07741898e-05 1.69434879e-05 ... 1.87824407e-05\n",
            "  1.40612938e-05 2.07337162e-05]]\n",
            "X is [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "shape of x (784, 60000), shape of E transposed (60000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-1a4941f03786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mB1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0msecondpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecondpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \"\"\"\n\u001b[0;32m--> 561\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10305\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10306\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10307\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10308\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10309\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [200,784] vs. [784,10] [Op:Sub]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU_kVxL341KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29984564-ddae-449a-86b0-874a8097880e"
      },
      "source": [
        "#Unit tests\n",
        "xu = tf.Variable([[0.3,0.2,0.1],\n",
        "                  [0.7,0.6,0.5],\n",
        "                  [0.2,0.2,0.2]])\n",
        "big = tf.Variable([[6.0,8.0,10.0]], shape = [1,3])\n",
        "small = tf.Variable([5.0,7.0,9.0])\n",
        "E = tf.math.subtract(big, small)\n",
        "minus_E = tf.math.subtract(small, big)\n",
        "print(loss_function(E, xu)) # should be xu/3\n",
        "print(loss_function(minus_E, xu)) # should be -xu/3"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x (3, 3), shape of E transposed (3, 1)\n",
            "(<tf.Tensor: shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
            "array([[0.6],\n",
            "       [1.8],\n",
            "       [0.6]], dtype=float32)>)\n",
            "shape of x (3, 3), shape of E transposed (3, 1)\n",
            "(<tf.Tensor: shape=(), dtype=float32, numpy=-3.0>, <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
            "array([[-0.6],\n",
            "       [-1.8],\n",
            "       [-0.6]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8I_oeqYZvUW",
        "outputId": "9355a14b-c3a4-42b9-e782-34191623a4bb"
      },
      "source": [
        "scalar = tf.Variable(3.0)\n",
        "vector = tf.Variable([3,6,9], dtype=tf.float32)\n",
        "prod = tf.scalar_mul(scalar, vector)\n",
        "prod"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 9., 18., 27.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5jDdWo_YFqw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}