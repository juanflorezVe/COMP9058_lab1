{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r00184264_juanflorez_assg1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6EbWveOwBl/CysT0vSaT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanflorezVe/COMP9058_lab1/blob/master/r00184264_juanflorez_assg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJivgFpXEloh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9KfcjsB09Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f708762-4ea0-4cbe-cd76-0b40c1e2109c"
      },
      "source": [
        "# Copying vervatim the code from the assignment\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1I7TLooA7uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e2f3c4-4db6-4b37-bd6d-4ac2612b9bf8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load the training and test data    \n",
        "(tr_x, tr_y), (te_x, te_y) = fashion_mnist.load_data()\n",
        "\n",
        "# reshape the feature data\n",
        "tr_x = tr_x.reshape(tr_x.shape[0], 784)\n",
        "te_x = te_x.reshape(te_x.shape[0], 784)\n",
        "\n",
        "# noramlise feature data\n",
        "tr_x = tr_x / 255.0\n",
        "te_x = te_x / 255.0\n",
        "\n",
        "print( \"Shape of training features \", tr_x.shape)\n",
        "print( \"Shape of test features \", te_x.shape)\n",
        "\n",
        "\n",
        "# one hot encode the training labels and get the transpose\n",
        "tr_y = np_utils.to_categorical(tr_y,10)\n",
        "tr_y = tr_y.T\n",
        "print (\"Shape of training labels \", tr_y.shape)\n",
        "\n",
        "# one hot encode the test labels and get the transpose\n",
        "te_y = np_utils.to_categorical(te_y,10)\n",
        "te_y = te_y.T\n",
        "print (\"Shape of testing labels \", te_y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Shape of training features  (60000, 784)\n",
            "Shape of test features  (10000, 784)\n",
            "Shape of training labels  (10, 60000)\n",
            "Shape of testing labels  (10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3EDtg1FocI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b21e1f8-7432-4b60-c8f0-5a8cffc0f819"
      },
      "source": [
        "# from lecture (VectorizedLogistiRegression, page 50) March 9th.... \n",
        "# We have a set of trainning of 60000 rows (instances)\n",
        "# and 748 columns ( Features)\n",
        "# Our X vector has 784 rows (as fetarues) and 60000 columns (instances)\n",
        "X = tf.Variable(tr_x.T, dtype = 'float32')\n",
        "print(\"X shape is {}\".format( X.shape))\n",
        "# Let's create a vector W1 with the number of weights (784) for each neuron in one row\n",
        "# so, it means 200 rows and 784 columns ( Features) for layer 1\n",
        "W1 = tf.Variable(tf.random.normal([ 200,784], mean=0.0, stddev=0.05))\n",
        "#The bias for the first layer of 200 neurons will be a vecoter of 200 rows (1 per neuron)\n",
        "# and 1 column\n",
        "B1 = tf.Variable([0.0]*200)\n",
        "B1 = tf.transpose(B1)\n",
        "print (\"W1 shape is{}\".format(W1.shape))\n",
        "print (\"B1 shape is{}\".format(B1.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape is (784, 60000)\n",
            "W1 shape is(200, 784)\n",
            "B1 shape is(200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC6WZg8RFp19"
      },
      "source": [
        "Question 1, section a. Question1_1_1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQYxA1J1SzoQ"
      },
      "source": [
        "# Let's implement the final softmax layer L2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndS5ol5F6VM"
      },
      "source": [
        "L2 = tf.Variable(tf.random.normal([10, 1], mean=0.0, stddev=0.05))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW6xG40UTQdw",
        "outputId": "c88ec0ce-57a5-4636-d04c-75ece479060a"
      },
      "source": [
        "L2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
              "array([[ 0.00175995],\n",
              "       [ 0.05755138],\n",
              "       [ 0.00603519],\n",
              "       [-0.08266527],\n",
              "       [ 0.00290031],\n",
              "       [ 0.02845798],\n",
              "       [-0.04208099],\n",
              "       [-0.06879644],\n",
              "       [-0.0847582 ],\n",
              "       [-0.0654161 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLfLKaoqUF2e"
      },
      "source": [
        "#Let's insert 784 parameters to each neuron\n",
        "# A = W.T * X + b\n",
        "b = tf.Variable([0.])\n",
        "A = tf.matmul(tf.transpose(W), tr_x) + b\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHo4xMShUmHX",
        "outputId": "c47eea8d-0b59-447b-8697-7b73c4946fae"
      },
      "source": [
        "A.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VirrA6HuVUVb",
        "outputId": "8a12800d-d150-4632-9d3f-13763e404aac"
      },
      "source": [
        "L2.shape\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meCoeCgQYgiS"
      },
      "source": [
        "#Review slide 33 of VectorizedLogisticRgression\n"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}